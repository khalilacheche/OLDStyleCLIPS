# Story
The project "OLDStyleCLIPS: Empowering Image Editing with Textual Guidance using StyleGAN Latent Space Optimization, CLIP, and Image Segmentation" is a collaborative effort by me, Farah Briki, and Haitao Zhou. It was done as part of the course "Computational Photography" at EPFL. The project was supervised by Dr. Ehsan Pajouheshgar.

# What
This project focuses on text-based image editing using StyleGAN2. It involves the manipulation of images based on textual guidance. The project's core objective is to enable users to edit images by providing textual instructions.
# How
The project leverages a combination of tools and technologies:

StyleGAN Latent Space Optimization: StyleGAN2 is used as the core framework for generating and manipulating images. Latent space optimization techniques are employed to achieve the desired image transformations.
CLIP: The project integrates OpenAI's CLIP model to enable text-based guidance for image manipulation. CLIP's ability to understand text and images adds a new dimension to the editing process.
Image Segmentation: Image segmentation techniques are applied to identify and manipulate specific regions of images, allowing for targeted edits.
# Challenges
The main challenge was incorporating the image segmentation module into the project.
# Result
This project, inspired by the research paper StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery by Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski, and Daniel Cohen, and LELSD: OPTIMIZING LATENT SPACE DIRECTIONS FOR GAN-BASED LOCAL IMAGE EDITING by Ehsan Pajouheshgar, Tong Zhang, and Sabine SÃ¼sstrunk, has successfully empowered text-based image editing using StyleGAN2.

The project's repository structure includes notebooks for image editing and inversion, model wrappers, utility functions, licenses, image assets, optimization code, pretrained model weights, and criteria wrappers, all organized to support the project's objectives.